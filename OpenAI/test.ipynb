{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory,ConversationBufferWindowMemory\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    PromptTemplate,\n",
    ")\n",
    "import os\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMChain\nprompt\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m\n\u001b[0;32m     25\u001b[0m     chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm_chain\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chain\n\u001b[1;32m---> 29\u001b[0m \u001b[43mnormal_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere is japan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m, in \u001b[0;36mnormal_llm\u001b[1;34m(user_input)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormal_llm\u001b[39m(user_input):\n\u001b[1;32m---> 12\u001b[0m     llm_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[0;32m     14\u001b[0m     [\n\u001b[0;32m     15\u001b[0m         (\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     ]\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     25\u001b[0m     chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm_chain\n",
      "File \u001b[1;32mc:\\Users\\berkg\\anaconda3\\envs\\openai\\Lib\\site-packages\\langchain_core\\load\\serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\berkg\\anaconda3\\envs\\openai\\Lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for LLMChain\nprompt\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"Your name is  Assistant. You are a personal assistant .You help users to learn  fundamentals and techniques with detailed answers. \n",
    "              helps people to practice  with the help of a projector and a indoor green platform so you might be asked to project a  practice on green.\n",
    "             if you do not know the answer, do not make up an answer, say that you do not know the answer.\n",
    "             Answer within 3 sentences to the user's question based on the context: {context}\"\"\"),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\",\"{input}\")\n",
    "            ])\n",
    "llm = ChatOpenAI(model_name=finetuned_model, temperature=0)\n",
    "def normal_llm(user_input):\n",
    "    \n",
    "    llm_chain = LLMChain(prompt=user_input, llm=llm)\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "    \n",
    "    chain = prompt | llm_chain\n",
    "\n",
    "    return chain\n",
    "\n",
    "normal_llm(\"where is japan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "job_id = 'ftjob-hjLV1XIM6ccPjzx6zTpAYw5z'\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "finetuned_job = client.fine_tuning.jobs.retrieve(job_id)\n",
    "finetuned_model = finetuned_job.fine_tuned_model\n",
    "\n",
    "loader = PyPDFLoader(\"../_RAG_3.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=80)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=finetuned_model, temperature=0)\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    llm=llm,\n",
    "    output_key='answer',\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True)\n",
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    get_chat_history=lambda h : h,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    Your name is  Assistant. You are a personal assistant . Recommend ideal  exercises to help users to improve their  skills.\n",
    "    You help users to learn  fundamentals and techniques with detailed answers. You also enlight users about  products. Give answers with 2 or 3 sentences, not longer.\n",
    "    \"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate\n",
    "chain.combine_docs_chain.llm_chain.prompt.messages[0] = SystemMessagePromptTemplate(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what are the  products',\n",
       " 'chat_history': [HumanMessage(content='what is  X?'),\n",
       "  AIMessage(content=' X is a professional  and training system. It is a great choice . It offers a wide range of features to improve your  skills. '),\n",
       "  HumanMessage(content='what is  X?'),\n",
       "  AIMessage(content=' X is a high-end  solution for indoor and outdoor practice. It offers real-time green visualization, allowing you to see the ideal putt and your actual putt simultaneously. With its advanced features,  X is a great choice for serious golfers looking to improve their  performance.')],\n",
       " 'answer': ' offers a range of products for different needs. The home series is perfect for home use, while the professional series is great for coaches and pros. The custom series allows for personalized solutions.',\n",
       " 'source_documents': [Document(page_content='correctly\\nwith\\nyour\\nputter\\nsquare\\nto\\nyour\\ntarget,\\nyou\\nare\\nlikely\\nto\\nhit\\nyour\\nputt\\ndown\\nyour\\ntarget\\nline.\\nThis\\nis\\nwhy\\nit\\nis\\nSO\\nimportant\\nto\\nkeep\\nyour\\nhands\\nquiet\\nthroughout\\nthe\\nstroke.\\nThese\\ntwo\\n\\ndrills\\nwill\\nreveal\\nyour\\nbest\\n\\nstroke\\nand\\none\\nthat\\nwill\\nbe\\neasiest\\nfor\\nyou\\nto\\nrepeat.\\nBest\\nGolf\\nClothing\\nand\\nGears:\\nAs\\na\\ngolf\\ncoach\\nI\\nwear\\ngolf\\nclothes\\nevery\\nday\\nof\\nmy\\nlife.\\nThey’re\\ncomfortable.\\nThey’re\\njust\\ndressy\\nenough.\\nAnd,\\nthey’re\\njust\\ncasual\\nenough.\\nLight\\ncolors\\nmight\\nbe\\na\\nbetter\\nchoice\\nto\\nwear\\nto\\nkeep\\nmosquitos\\naway\\nin\\nthe\\ngolf\\ncourse.\\nWhat\\nto\\ndo\\nIf\\n\\nsystem\\ndoes\\nnot\\nwork?\\n-\\nIf\\n\\nsystem\\ndoes\\nnot\\nwork\\nanymore,\\nyou\\ncan\\ncontact\\nwith\\n\\nsupport\\nand\\nyou\\ncan\\nfind\\nquick\\nhelp,\\nproblem-solving\\nresources.\\nYou\\ncan\\ncontact\\n\\nsupport\\nvia\\nemail\\n:\\nsupport@ .com\\n.\\nI\\nwant\\nto\\nbuy\\na\\n\\nsystem,\\nwhat\\ncan\\nI\\ndo?\\n-\\nIf\\nyou\\nwant\\nto\\nbut\\na\\n\\nsystem,\\nyou\\ncan\\ncontact\\nwith\\nSales\\nvia\\nemail\\n:\\nsales@ .com\\n.', metadata={'source': '../_RAG_3.pdf', 'page': 16}),\n",
       "  Document(page_content=\"setup.\\nWhether\\nyou're\\ninterested\\nin\\ninstalling\\nPuttV iew\\nonto\\nan\\nexisting\\ngreen\\nor\\nintegrating\\nit\\ninto\\nyour\\nsimulator ,\\nwe\\nhave\\nthe\\nperfect\\nsolution\\nfor\\nyour\\nneeds.\\nPuttV iew\\nCustom\\nSeries\\nare\\ngreat\\noptions\\nfor\\nlarge\\nspaces,\\neven\\nfor\\nfacilities.\\nFacilities\\ncan\\nhost\\nPuttV iew\\nevents\\nand\\ntournaments\\nand\\nlet\\nguests\\nplay\\nmultiplayer\\ngames\\nand\\nrent\\nthe\\nsystem\\nto\\ngroups.\\nIt\\nis\\nalso\\npossible\\nto\\nPractice\\nwith\\nup\\nto\\nsix\\npeople\\nat\\nthe\\nsame\\ntime\\nand\\nget\\nvaluable\\ninsights\\ninto\\neach\\nindividual's\\n\\nperformance.\\nThere\\nare\\n4\\ntypes\\nof\\nPuttV iew\\nCustom\\nSeries:\\nCX1,\\nCX2,\\nC1\\nand\\nC2.\\nC1\\nand\\nCX1\\nprovide\\nup\\nto\\n270\\nfeet\\nsquare\\nprojection\\narea.\\nC2\\nand\\nCX2\\nprovide\\nup\\nto\\n540\\nfeet\\nsquare\\nprojection\\narea.\\nPuttV iew\\nCustom\\nSeries\\nare\\none\\nof\\nthe\\nmost\\npremium\\nproducts\\nof\\nPuttV iew.\\n7.1.4\\n\\nMoving\\nSeries\\nThe\\nMoving\\nSeries\\nis\\nan\\nall-encompassing\\n\\nimprovement\\nsolution\\nfor\\nyour\\nhome\\nor\\nstudio.It\\nis\\npossible\\nto\\nrecreate\\n\\nscenarios\\nfrom\\nany\\ngolf\\ncourse\\nand\\nenjoy\\nthe\\nsmooth\\nand\\naccurate\\nslope\", metadata={'source': '../_RAG_3.pdf', 'page': 12})]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain({\"question\": \"what are the  products\"})\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
