# LLMs
- Generative AI Applications

- Finetuning open source LLMs such as Mistral 7B, Llama 7B, Zephyr 7B


- Integrating RAG and chat memory into the finetuned LLMs


- Performing inference with Llamacpp on local machines including both CPU and GPU


- Employing OpenAI models with finetuning + RAG as personal assistants.


- Deploying LLMs as web apps using React and Flask on Azure Web services.

# Use

- In order to perform fine-tuning and the inference, the scripts that are in FineTune/INSTRUCT/ directory can be used.
- RAG performance can be tested using the jupyter notebook RAG/RAG_faiss.ipynb
- The assistant can also be performed using the full-stack application which can be found under Chatbot_Apps/Flask_React_chat directory.

