{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home//miniconda3/envs/torch2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import (\n",
    "    StreamingStdOutCallbackHandler\n",
    ")\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter,CharacterTextSplitter\n",
    "from huggingface_hub import hf_hub_download\n",
    "from langchain.llms import LlamaCpp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_template = \"\"\"You are a personal assistant . Help users to learn  fundamentals and techniques.\n",
    "### Instruction: {question}\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "prompt_main = PromptTemplate(template=main_template, input_variables=[\"question\"])\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'CMAKE_ARGS' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"_RAG.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 23 key-value pairs and 291 tensors from /home//.cache/huggingface/hub/models--berkouille--Mistral_Golf_GGUF/snapshots/8648d6b1eab8fa3845331a7df007c81f334aa190/ggml-model18-q4.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = 7B\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 3\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_1:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_1\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.24 GiB (5.03 BPW) \n",
      "llm_load_print_meta: general.name     = 7B\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 2 '</s>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.33 MiB\n",
      "llm_load_tensors: offloading 32 repeating layers to GPU\n",
      "llm_load_tensors: offloading non-repeating layers to GPU\n",
      "llm_load_tensors: offloaded 33/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =    78.12 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =  2210.53 MiB\n",
      "llm_load_tensors:      CUDA1 buffer size =  2053.02 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 6000\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =   398.44 MiB\n",
      "llama_kv_cache_init:      CUDA1 KV buffer size =   351.56 MiB\n",
      "llama_new_context_with_model: KV self size  =  750.00 MiB, K (f16):  375.00 MiB, V (f16):  375.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host input buffer size   =     1.18 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =    26.47 MiB\n",
      "llama_new_context_with_model:      CUDA1 compute buffer size =    26.47 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =     0.52 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 5\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n",
      "Model metadata: {'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': '7B', 'tokenizer.ggml.add_bos_token': 'true', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '3'}\n"
     ]
    }
   ],
   "source": [
    "(repo_id, model_file_name) = (\"\",\n",
    "                                  \"ggml-model18-q4.gguf\")\n",
    "\n",
    "model_path = hf_hub_download(repo_id=repo_id,\n",
    "                                 filename=model_file_name,\n",
    "                                 repo_type=\"model\")\n",
    "llm = LlamaCpp(\n",
    "        model_path=model_path,\n",
    "        n_gpu_layers=512,\n",
    "        n_batch=30,\n",
    "        n_ctx=6000,\n",
    "        max_tokens=200,\n",
    "        temperature=0,\n",
    "        # callback_manager=callback_manager,\n",
    "        verbose=True,\n",
    "        streaming=True,\n",
    "        )\n",
    "\n",
    "llm_chain_main = LLMChain(prompt=prompt_main, llm=llm)\n",
    "\n",
    "loader = PyPDFLoader(\"_RAG.pdf\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "hf_embedding = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")\n",
    "\n",
    "db = FAISS.from_documents(docs, hf_embedding)\n",
    "db.save_local(\"_FAISS\")\n",
    "# load from local\n",
    "db = FAISS.load_local(\"_FAISS/\", embeddings=hf_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-gpu in /home//miniconda3/envs/torch2/lib/python3.9/site-packages (1.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home//miniconda3/envs/torch2/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "\n",
      "llama_print_timings:        load time =      65.71 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    39 runs   (    0.11 ms per token,  8709.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     431.14 ms /   200 tokens (    2.16 ms per token,   463.89 tokens per second)\n",
      "llama_print_timings:        eval time =     382.38 ms /    38 runs   (   10.06 ms per token,    99.38 tokens per second)\n",
      "llama_print_timings:       total time =     882.18 ms /   238 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed control is crucial on the green. To improve, focus on your line, distance, and speed. Practice with short putts, progressively increasing distance as you gain confidence.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =      65.71 ms\n",
      "llama_print_timings:      sample time =      22.52 ms /   200 runs   (    0.11 ms per token,  8881.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2575.74 ms /  1193 tokens (    2.16 ms per token,   463.17 tokens per second)\n",
      "llama_print_timings:        eval time =    2150.34 ms /   199 runs   (   10.81 ms per token,    92.54 tokens per second)\n",
      "llama_print_timings:       total time =    5121.76 ms /  1392 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. Stance: In  practice, it's crucial to establish a consistent and comfortable stance. This involves setting the feet shoulder-width apart, aligning them parallel to the target line, and ensuring a slight bend in the knees. A stable and balanced stance provides a solid foundation for a controlled  stroke. \n",
      " \n",
      " 2. Line: The line is all about the intended path the ball should take to reach the hole. During  practice, golfers focus on aligning the putter face to this desired line. This involves careful aim and precision to ensure that the ball starts on the correct path. \n",
      " \n",
      " 3. Speed: Speed control is a critical aspect of  practice, emphasizing how hard or soft a golfer strikes the ball. Practicing various distances and green speeds helps golfers develop a consistent feel for how much force to apply to achieve the desired putt length. It involves refining touch and judgment to adapt to different green conditions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =      65.71 ms\n",
      "llama_print_timings:      sample time =       5.52 ms /    49 runs   (    0.11 ms per token,  8880.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2499.95 ms /  1167 tokens (    2.14 ms per token,   466.81 tokens per second)\n",
      "llama_print_timings:        eval time =     528.76 ms /    48 runs   (   11.02 ms per token,    90.78 tokens per second)\n",
      "llama_print_timings:       total time =    3153.59 ms /  1215 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Improving your  skills involves consistent practice, proper technique, and mental focus. We can work on your aiming, distance control, and green reading. I'll also provide feedback and motivation to help you reach your goals.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =      65.71 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    67 runs   (    0.12 ms per token,  8618.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.89 ms /   634 tokens (    2.18 ms per token,   459.46 tokens per second)\n",
      "llama_print_timings:        eval time =     714.23 ms /    66 runs   (   10.82 ms per token,    92.41 tokens per second)\n",
      "llama_print_timings:       total time =    2233.29 ms /   700 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ladder drills focus on distance control, Straight putts hone alignment, Star drills improve green reading, Rolling Balls demonstrate ideal ball motion, Random Putts enhance pressure putt skills, Hole Out Challange tests distance accuracy, and Challange Zone aims to improve speed control under pressure.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =      65.71 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    78 runs   (    0.11 ms per token,  8979.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1632.15 ms /   764 tokens (    2.14 ms per token,   468.09 tokens per second)\n",
      "llama_print_timings:        eval time =     822.63 ms /    77 runs   (   10.68 ms per token,    93.60 tokens per second)\n",
      "llama_print_timings:       total time =    2609.74 ms /   841 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green reading is the ability to accurately determine the line and speed of a putt based on the green's topography.  helps improve green reading by providing visual cues such as contour lines, slope arrows, and slope percentage. These visuals help golfers understand the green's slope and break better, leading to more accurate putts. \n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =      65.71 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    51 runs   (    0.11 ms per token,  8909.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2665.78 ms /  1222 tokens (    2.18 ms per token,   458.40 tokens per second)\n",
      "llama_print_timings:        eval time =     550.63 ms /    50 runs   (   11.01 ms per token,    90.81 tokens per second)\n",
      "llama_print_timings:       total time =    3350.40 ms /  1272 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Distance accuracy refers to the consistency with which you hit your putts at the intended speed. 's real-time feedback and drills can help improve your distance accuracy by providing visual cues and tracking your progress. \n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =      65.71 ms\n",
      "llama_print_timings:      sample time =      21.46 ms /   200 runs   (    0.11 ms per token,  9320.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2638.54 ms /  1216 tokens (    2.17 ms per token,   460.86 tokens per second)\n",
      "llama_print_timings:        eval time =    2162.59 ms /   199 runs   (   10.87 ms per token,    92.02 tokens per second)\n",
      "llama_print_timings:       total time =    5202.26 ms /  1415 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  offers various games such as PuttPong, Maze, Shooter, Splash, Tic-Tac-Put, PuttPong, Maze, Shooter, Splash, Tic-Tac-Put, PuttPong, Maze, Shooter, Splash, Tic-Tac-Put, PuttPong, Maze, Shooter, Splash, Tic-Tac-Put, PuttPong, Maze, Shooter, Splash, Tic-Tac-Put, PuttPong, Maze, Shooter, Splash, Tic-Tac-Put, PuttPong, Maze, Shooter, Splash, Tic-Tac-Put, PuttPong, Maze, Shooter, Splash, Tic-Tac-Put,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =      65.71 ms\n",
      "llama_print_timings:      sample time =       5.92 ms /    51 runs   (    0.12 ms per token,  8611.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2661.55 ms /  1222 tokens (    2.18 ms per token,   459.13 tokens per second)\n",
      "llama_print_timings:        eval time =     546.87 ms /    50 runs   (   10.94 ms per token,    91.43 tokens per second)\n",
      "llama_print_timings:       total time =    3348.70 ms /  1272 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning how to putt effectively involves practicing key skills such as distance control, green reading, and maintaining a consistent stroke. Utilize 's visual cues, drills, and feedback to improve your  performance.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =      65.71 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /    34 runs   (    0.11 ms per token,  9001.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1535.39 ms /   715 tokens (    2.15 ms per token,   465.68 tokens per second)\n",
      "llama_print_timings:        eval time =     350.94 ms /    33 runs   (   10.63 ms per token,    94.03 tokens per second)\n",
      "llama_print_timings:       total time =    1968.69 ms /   748 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you know that the average distance for a putt on the PGA Tour is just over 17 feet? That's pretty impressive accuracy!\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =      65.71 ms\n",
      "llama_print_timings:      sample time =      17.83 ms /   159 runs   (    0.11 ms per token,  8917.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2630.80 ms /  1205 tokens (    2.18 ms per token,   458.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1722.99 ms /   158 runs   (   10.90 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:       total time =    4684.70 ms /  1363 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing the correct putter is crucial for your golf game. Here are some key factors to consider when selecting a putter: 1. Length: Determine the ideal putter length that suits your height and posture. 2. Grip: Test different grip sizes to find one that provides comfort and control. 3. Head Design: Experiment with various head designs to assess their impact on alignment and confidence. 4. Hosel Configuration: Consider the hosel configuration (open or closed) based on your aiming preferences. 5. Testing: Don't hesitate to ask for help from  staff or use the  technology to test different putters and find the one that suits your  style. \n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a  coach, I would recommend starting with short putts to build confidence and accuracy. We can also focus on alignment, green reading, and distance control using 's visual cues and feedback.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =      65.71 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /    47 runs   (    0.11 ms per token,  8793.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2608.63 ms /  1195 tokens (    2.18 ms per token,   458.09 tokens per second)\n",
      "llama_print_timings:        eval time =     509.83 ms /    46 runs   (   11.08 ms per token,    90.23 tokens per second)\n",
      "llama_print_timings:       total time =    3244.77 ms /  1241 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'query = \"I am pretty bad at speed control, can you help me?\"\\nsearch = db.similarity_search(query, k=2)\\nprompt = PromptTemplate(input_variables=[\"context\", \"question\"], template= template_1)\\nfinal_prompt = prompt.format(question=query, context=search)\\nrag_out = llm_chain_main.run(final_prompt)\\nrag_out'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_1 = '''Context: {context}\n",
    "Based on the Context, provide an answer as a  coach for following question\n",
    "### Instruction:{question}\n",
    "'''\n",
    "\n",
    "questions = [\"What is the best way to control speed on the green?\",\n",
    "             \"Explain main aspects of .\",\n",
    "             \"How can i get better at  ?\",\n",
    "             \"Explain ladder drills, start drills, rolling balls, hole out challange and challange zone. What are they used for. \",\n",
    "             \"what is green reading and how to improve it with ? \",\n",
    "             \"what is distance accuracy and how to improve it with ? \",\n",
    "             \"What are the games in ?\",\n",
    "             \"how do i learn how to putt?\",\n",
    "             \"tell me a random fact about .\",\n",
    "             \"how can i choose a correct putter for myself?\",\n",
    "             \"I am beginner where should i start ?\"]\n",
    "\n",
    "for question in questions:\n",
    "    search = db.similarity_search(question, k=2)\n",
    "    prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template= template_1)\n",
    "    final_prompt = prompt.format(question=question, context=search)\n",
    "    rag_out = llm_chain_main.run(final_prompt)\n",
    "    print(rag_out)\n",
    "    time.sleep(1)\n",
    "\n",
    "\"\"\"query = \"I am pretty bad at speed control, can you help me?\"\n",
    "search = db.similarity_search(query, k=2)\n",
    "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template= template_1)\n",
    "final_prompt = prompt.format(question=query, context=search)\n",
    "rag_out = llm_chain_main.run(final_prompt)\n",
    "rag_out\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Challenge Zone is an exercise designed to improve distance control on the greens. The goal is to play as many consecutive putts as possible, with each putt being shorter than the previous one. This challenge helps golfers hone their speed control skills, which are essential for successful .\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =      65.71 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    62 runs   (    0.11 ms per token,  9080.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =     654.96 ms /    62 runs   (   10.56 ms per token,    94.66 tokens per second)\n",
      "llama_print_timings:       total time =     754.97 ms /    63 tokens\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# test the speed\n",
    "question = input(\"Enter the question: \")\n",
    "search = db.similarity_search(question, k=2)\n",
    "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template= template_1)\n",
    "final_prompt = prompt.format(question=question, context=search)\n",
    "rag_out = llm_chain_main.run(final_prompt)\n",
    "print(rag_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ===== as retriever  =======\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 811, which is longer than the specified 500\n",
      "Created a chunk of size 609, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=500, \n",
    "                                      chunk_overlap=20)\n",
    "chunked_documents = text_splitter.split_documents(documents)\n",
    "db = FAISS.from_documents(chunked_documents, \n",
    "                          HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))\n",
    "\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template_1,\n",
    ")\n",
    "\n",
    "llm_chain_1 = LLMChain(llm=llm, prompt=prompt)\n",
    "#llm_chain.invoke({\"context\": \"\", \"question\": \"what are the games in ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'### Response: Improving  skills involves practicing key fundamentals and techniques. We can create a customized  training plan to help you enhance your accuracy, distance control, and mental focus on the greens.\\n    '"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "rag_chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain_1\n",
    ")\n",
    "\n",
    "result = rag_chain.invoke(query)\n",
    "result['text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
