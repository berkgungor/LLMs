{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "606986be-fd43-4b0f-b69b-02250e57e4b0",
   "metadata": {},
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9d6495-af97-405d-b4d6-63b322cb82d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U torch datasets transformers tensorflow langchain playwright html2text sentence_transformers faiss-cpu\n",
    "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 trl==0.4.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdda41-708b-4af8-88a9-5056cbd08bf4",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "505ca9a3-8c27-442e-bca6-154a65186d01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home//miniconda3/envs/torch2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-03 16:04:57.349911: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-03 16:04:57.349947: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-03 16:04:57.350785: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-03 16:04:57.354648: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-03 16:04:58.045871: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180f8d4e-a8bf-4389-b046-9827b310a3b3",
   "metadata": {},
   "source": [
    "### Load quantized Mistal 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f94e97-7e58-4253-9376-73af6f36e139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 1.47k/1.47k [00:00<00:00, 345kB/s]\n",
      "tokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 28.4MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.80M/1.80M [00:00<00:00, 3.84MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 72.0/72.0 [00:00<00:00, 106kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 571/571 [00:00<00:00, 151kB/s]\n",
      "model.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 25.4MB/s]\n",
      "model-00001-of-00002.safetensors: 100%|██████████| 9.94G/9.94G [05:29<00:00, 30.2MB/s]\n",
      "model-00002-of-00002.safetensors: 100%|██████████| 4.54G/4.54G [01:36<00:00, 47.1MB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [07:11<00:00, 215.76s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.41s/it]\n",
      "generation_config.json: 100%|██████████| 116/116 [00:00<00:00, 33.8kB/s]\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Tokenizer\n",
    "#################################################################\n",
    "\n",
    "model_name='mistralai/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "#################################################################\n",
    "# bitsandbytes parameters\n",
    "#################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb199a-a537-4bd7-9888-d43a84c8ff69",
   "metadata": {},
   "source": [
    "### Count number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91d2a86e-69e8-496f-b388-853168537c20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 262410240\n",
      "all model parameters: 3752071168\n",
      "percentage of trainable model parameters: 6.99%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38c760-f5c8-49c6-9c0c-80719557fee5",
   "metadata": {},
   "source": [
    "### Build Mistral text generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c613429-9e6c-4a1e-bc9c-579eb152434b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.3,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c859dd05-9114-42f1-81f2-52a28b7efdd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a07789-78f5-498c-987b-9ed3eb459fe6",
   "metadata": {},
   "source": [
    "### Load and chunk documents. Load chunked documents into FAISS index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35e625a4-8d25-453e-bef0-435a6e1aa135",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "Switching to root user to install dependencies...\n",
      "[sudo] password for : \n",
      "Traceback (most recent call last):\n",
      "  File \"/home//miniconda3/envs/torch2/bin/playwright\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home//miniconda3/envs/torch2/lib/python3.9/site-packages/playwright/__main__.py\", line 23, in main\n",
      "    completed_process = subprocess.run(\n",
      "  File \"/home//miniconda3/envs/torch2/lib/python3.9/subprocess.py\", line 507, in run\n",
      "    stdout, stderr = process.communicate(input, timeout=timeout)\n",
      "  File \"/home//miniconda3/envs/torch2/lib/python3.9/subprocess.py\", line 1126, in communicate\n",
      "    self.wait()\n",
      "  File \"/home//miniconda3/envs/torch2/lib/python3.9/subprocess.py\", line 1189, in wait\n",
      "    return self._wait(timeout=timeout)\n",
      "  File \"/home//miniconda3/envs/torch2/lib/python3.9/subprocess.py\", line 1933, in _wait\n",
      "    (pid, sts) = self._try_wait(0)\n",
      "  File \"/home//miniconda3/envs/torch2/lib/python3.9/subprocess.py\", line 1891, in _try_wait\n",
      "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
      "KeyboardInterrupt\n",
      "Sorry, try again.\n",
      "sudo: a terminal is required to read the password; either use the -S option to read from standard input or configure an askpass helper\n",
      "sudo: 1 incorrect password attempt\n",
      "ARGolfHH!\n"
     ]
    }
   ],
   "source": [
    "!playwright install \n",
    "!playwright install-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0aea1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79a2e41f-aee3-47ff-92a1-74970f3b313a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Articles to index\n",
    "articles = [\"https://www..com/blog/the-need-for-speed/\",\n",
    "            \"https://www..com/blog/improve-your-green-reading-with-these-easy-steps/\",\n",
    "            \"https://www..com/blog/make-the-most-out-of-your--practice/\",\n",
    "            \"https://www..com/products/indoor/features/\"]\n",
    "\n",
    "# Scrapes the blogs above\n",
    "loader = AsyncChromiumLoader(articles)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff328fea-b7c7-4ca3-915c-39c0ebaa2f7a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 671, which is longer than the specified 100\n",
      "Created a chunk of size 751, which is longer than the specified 100\n",
      "Created a chunk of size 127, which is longer than the specified 100\n",
      "Created a chunk of size 725, which is longer than the specified 100\n",
      "Created a chunk of size 163, which is longer than the specified 100\n",
      "Created a chunk of size 403, which is longer than the specified 100\n",
      "Created a chunk of size 344, which is longer than the specified 100\n",
      "Created a chunk of size 487, which is longer than the specified 100\n",
      "Created a chunk of size 381, which is longer than the specified 100\n",
      "Created a chunk of size 528, which is longer than the specified 100\n",
      "Created a chunk of size 103, which is longer than the specified 100\n",
      "Created a chunk of size 441, which is longer than the specified 100\n",
      "Created a chunk of size 827, which is longer than the specified 100\n",
      "Created a chunk of size 820, which is longer than the specified 100\n",
      "Created a chunk of size 196, which is longer than the specified 100\n",
      "Created a chunk of size 778, which is longer than the specified 100\n",
      "Created a chunk of size 554, which is longer than the specified 100\n",
      "Created a chunk of size 346, which is longer than the specified 100\n",
      "Created a chunk of size 116, which is longer than the specified 100\n",
      "Created a chunk of size 464, which is longer than the specified 100\n",
      "Created a chunk of size 392, which is longer than the specified 100\n",
      "Created a chunk of size 577, which is longer than the specified 100\n",
      "Created a chunk of size 404, which is longer than the specified 100\n",
      "Created a chunk of size 424, which is longer than the specified 100\n",
      "Created a chunk of size 359, which is longer than the specified 100\n",
      "Created a chunk of size 536, which is longer than the specified 100\n",
      "Created a chunk of size 103, which is longer than the specified 100\n",
      "Created a chunk of size 446, which is longer than the specified 100\n",
      "Created a chunk of size 415, which is longer than the specified 100\n",
      "Created a chunk of size 338, which is longer than the specified 100\n",
      "Created a chunk of size 130, which is longer than the specified 100\n",
      "Created a chunk of size 106, which is longer than the specified 100\n",
      "Created a chunk of size 128, which is longer than the specified 100\n",
      "Created a chunk of size 323, which is longer than the specified 100\n",
      "Created a chunk of size 917, which is longer than the specified 100\n",
      "Created a chunk of size 763, which is longer than the specified 100\n",
      "Created a chunk of size 946, which is longer than the specified 100\n",
      "Created a chunk of size 676, which is longer than the specified 100\n",
      "Created a chunk of size 1006, which is longer than the specified 100\n",
      "Created a chunk of size 749, which is longer than the specified 100\n",
      "Created a chunk of size 137, which is longer than the specified 100\n",
      "Created a chunk of size 366, which is longer than the specified 100\n",
      "Created a chunk of size 179, which is longer than the specified 100\n",
      "Created a chunk of size 636, which is longer than the specified 100\n",
      "Created a chunk of size 215, which is longer than the specified 100\n",
      "Created a chunk of size 751, which is longer than the specified 100\n",
      "Created a chunk of size 767, which is longer than the specified 100\n",
      "Created a chunk of size 673, which is longer than the specified 100\n",
      "Created a chunk of size 130, which is longer than the specified 100\n",
      "Created a chunk of size 224, which is longer than the specified 100\n",
      "Created a chunk of size 662, which is longer than the specified 100\n",
      "Created a chunk of size 767, which is longer than the specified 100\n",
      "Created a chunk of size 182, which is longer than the specified 100\n",
      "Created a chunk of size 1416, which is longer than the specified 100\n",
      "Created a chunk of size 1210, which is longer than the specified 100\n",
      "Created a chunk of size 184, which is longer than the specified 100\n",
      "Created a chunk of size 1173, which is longer than the specified 100\n",
      "Created a chunk of size 640, which is longer than the specified 100\n",
      "Created a chunk of size 139, which is longer than the specified 100\n",
      "Created a chunk of size 975, which is longer than the specified 100\n",
      "Created a chunk of size 195, which is longer than the specified 100\n",
      "Created a chunk of size 1421, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 1062, which is longer than the specified 100\n",
      "Created a chunk of size 868, which is longer than the specified 100\n",
      "Created a chunk of size 130, which is longer than the specified 100\n",
      "Created a chunk of size 348, which is longer than the specified 100\n",
      "Created a chunk of size 196, which is longer than the specified 100\n",
      "Created a chunk of size 110, which is longer than the specified 100\n",
      "Created a chunk of size 166, which is longer than the specified 100\n",
      "Created a chunk of size 175, which is longer than the specified 100\n",
      "Created a chunk of size 156, which is longer than the specified 100\n",
      "Created a chunk of size 223, which is longer than the specified 100\n",
      "Created a chunk of size 220, which is longer than the specified 100\n",
      "Created a chunk of size 221, which is longer than the specified 100\n",
      "Created a chunk of size 221, which is longer than the specified 100\n",
      "Created a chunk of size 220, which is longer than the specified 100\n",
      "Created a chunk of size 219, which is longer than the specified 100\n",
      "Created a chunk of size 220, which is longer than the specified 100\n",
      "Created a chunk of size 220, which is longer than the specified 100\n",
      "Created a chunk of size 221, which is longer than the specified 100\n",
      "Created a chunk of size 221, which is longer than the specified 100\n",
      "Created a chunk of size 220, which is longer than the specified 100\n",
      "Created a chunk of size 220, which is longer than the specified 100\n",
      "Created a chunk of size 170, which is longer than the specified 100\n",
      "Created a chunk of size 147, which is longer than the specified 100\n",
      "Created a chunk of size 127, which is longer than the specified 100\n",
      "Created a chunk of size 140, which is longer than the specified 100\n",
      "Created a chunk of size 109, which is longer than the specified 100\n",
      "Created a chunk of size 159, which is longer than the specified 100\n",
      "Created a chunk of size 110, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 186, which is longer than the specified 100\n",
      "Created a chunk of size 119, which is longer than the specified 100\n",
      "Created a chunk of size 107, which is longer than the specified 100\n",
      "Created a chunk of size 126, which is longer than the specified 100\n",
      "Created a chunk of size 126, which is longer than the specified 100\n",
      "Created a chunk of size 125, which is longer than the specified 100\n",
      "Created a chunk of size 110, which is longer than the specified 100\n",
      "Created a chunk of size 132, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 218, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 109, which is longer than the specified 100\n",
      "Created a chunk of size 128, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 230, which is longer than the specified 100\n",
      "Created a chunk of size 163, which is longer than the specified 100\n",
      "Created a chunk of size 121, which is longer than the specified 100\n",
      "Created a chunk of size 104, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 168, which is longer than the specified 100\n",
      "Created a chunk of size 194, which is longer than the specified 100\n",
      "Created a chunk of size 147, which is longer than the specified 100\n",
      "Created a chunk of size 177, which is longer than the specified 100\n",
      "Created a chunk of size 126, which is longer than the specified 100\n",
      "Created a chunk of size 704, which is longer than the specified 100\n",
      "Created a chunk of size 222, which is longer than the specified 100\n",
      "Created a chunk of size 251, which is longer than the specified 100\n",
      "Created a chunk of size 291, which is longer than the specified 100\n",
      "Created a chunk of size 205, which is longer than the specified 100\n",
      "Created a chunk of size 235, which is longer than the specified 100\n",
      "Created a chunk of size 239, which is longer than the specified 100\n",
      "Created a chunk of size 305, which is longer than the specified 100\n",
      "Created a chunk of size 428, which is longer than the specified 100\n",
      "Created a chunk of size 458, which is longer than the specified 100\n",
      "Created a chunk of size 352, which is longer than the specified 100\n",
      "Created a chunk of size 448, which is longer than the specified 100\n",
      "Created a chunk of size 440, which is longer than the specified 100\n",
      "Created a chunk of size 200, which is longer than the specified 100\n",
      "Created a chunk of size 257, which is longer than the specified 100\n",
      "Created a chunk of size 339, which is longer than the specified 100\n",
      "Created a chunk of size 524, which is longer than the specified 100\n",
      "Created a chunk of size 262, which is longer than the specified 100\n",
      "Created a chunk of size 237, which is longer than the specified 100\n",
      "Created a chunk of size 179, which is longer than the specified 100\n",
      "Created a chunk of size 326, which is longer than the specified 100\n",
      "Created a chunk of size 212, which is longer than the specified 100\n",
      "Created a chunk of size 315, which is longer than the specified 100\n",
      "Created a chunk of size 295, which is longer than the specified 100\n",
      "Created a chunk of size 382, which is longer than the specified 100\n",
      "Created a chunk of size 233, which is longer than the specified 100\n",
      "Created a chunk of size 218, which is longer than the specified 100\n",
      "Created a chunk of size 248, which is longer than the specified 100\n",
      "Created a chunk of size 313, which is longer than the specified 100\n",
      "Created a chunk of size 298, which is longer than the specified 100\n",
      "Created a chunk of size 301, which is longer than the specified 100\n",
      "Created a chunk of size 240, which is longer than the specified 100\n",
      "Created a chunk of size 202, which is longer than the specified 100\n",
      "Created a chunk of size 201, which is longer than the specified 100\n",
      "Created a chunk of size 325, which is longer than the specified 100\n",
      "Created a chunk of size 103, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 130, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "# Converts HTML to plain text \n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)\n",
    "\n",
    "# Chunk text\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, \n",
    "                                      chunk_overlap=0)\n",
    "chunked_documents = text_splitter.split_documents(docs_transformed)\n",
    "\n",
    "# Load chunked documents into the FAISS index\n",
    "db = FAISS.from_documents(chunked_documents, \n",
    "                          HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))\n",
    "\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d54a0b-bf6c-4a24-b888-4c3283b9ccf6",
   "metadata": {},
   "source": [
    "### Create PromptTemplate and LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bd688c2-25ac-4d65-88c6-635f9c95ada4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "### [INST] Instruction: Answer the question as an indoor  coach. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} [/INST]\n",
    " \"\"\"\n",
    "\n",
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "727e50d1-5739-4a65-8745-aaa4c9c47189",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home//miniconda3/envs/torch2/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': '',\n",
       " 'question': 'what are main aspects of ?',\n",
       " 'text': \"\\nAs an indoor  coach, I would say that there are several key aspects to focus on when practicing  indoors. These include:\\n\\n1. Proper stance and posture: It's important to stand with your feet shoulder-width apart and your body weight evenly distributed between your feet. Your knees should be slightly bent and your back straight.\\n2. Correct grip: Hold the putter with your dominant hand on the top of the shaft and your non-dominant hand on the bottom. Make sure your grip is firm but not too tight.\\n3. Smooth swing: Practice making smooth, consistent swings with your putter. Focus on keeping your arms and shoulders relaxed and your body moving in a fluid motion.\\n4. Aim and target: When , it's important to aim for the center of the green and keep your eye on the ball as you swing. This will help you make more accurate shots.\\n5.\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke({\"context\": \"\", \"question\": \"what are main aspects of ?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e75d34-cf63-49a8-a671-88ccb5444367",
   "metadata": {},
   "source": [
    "### Build RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1e18178-46f2-4b87-86c4-d13ff5219968",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home//miniconda3/envs/torch2/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "rag_chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")\n",
    "\n",
    "result = rag_chain.invoke(\"what are the best drills for green reading?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef54e9e3-4fa5-4676-baaf-8b11e3f09dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='* Practice\\n* References\\n* Contact\\n* Get Your Own \\n* * #  Improve your green reading with these easy steps', metadata={'source': 'https://www..com/blog/improve-your-green-reading-with-these-easy-steps/'}),\n",
       " Document(page_content='3 easy ways to improve your green reading', metadata={'source': 'https://www..com/blog/improve-your-green-reading-with-these-easy-steps/'}),\n",
       " Document(page_content='Now, that you have figured out which type of player you are, we can shift the\\nfocus to improving your green reading skills. By following these three simple\\nsteps, you can become a better green reader no matter if you are a straight\\nline or a curved line thinker. Make sure, that you incorporate those tips\\nregularly into your practice and you will see quick results.', metadata={'source': 'https://www..com/blog/improve-your-green-reading-with-these-easy-steps/'}),\n",
       " Document(page_content='As easy and boring as this might seem to you, inside those 10 ft you can still\\nface significant trouble due to break, bringing us back to the remaining two\\nskill sets read and speed. Let’s start with the green-reading aspect. When\\nchoosing a  tool, it is important that you have both left-to-right and\\nright-to-left breaking putts. Being able to read those breaks correctly, is a\\nvery essential skill to have. For example, in every green offered in our\\nportfolio, including our P7 and P7 Plus Home Series that is specifically\\ndesigned to fit into smaller spaces, we were focused on incorporating all\\nthose important breaks and distances. Furthermore, you should be able to\\nunderstand that every golfer has a bias and a break that they feel more\\ncomfortable with than the other. Knowing your bias will help you improve your\\n significantly. Therefore, it can also be very helpful to keep track of\\nyour shot pattern. If you own a  system, you can analyze your data by\\nlooking at your shot patterns. It will help you appreciate your misses and in\\ncombination with visual cues such as the Ideal Line, you can easily figure out\\nif you tend to overread or underread your putts and work on those specific\\nproblems. In case you want to know more about how you can practice your green\\nreading and analyze your tendencies, you can also head over to our Best\\nPractice Site and have a look at some useful drills.', metadata={'source': 'https://www..com/blog/make-the-most-out-of-your--practice/'})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62895f39-9dfb-4f58-8312-72580ca03a20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " As an indoor  coach, I would recommend practicing the following drills to improve your green reading skills:\n",
      "\n",
      "  1. Break Drill: This drill involves hitting putts with varying degrees of break from different angles and distances. The goal is to learn how to read and adjust for the break in your putts. You can use a  system to analyze your shot patterns and identify areas where you need to improve.\n",
      "   \n",
      "  2. Bias Drill: This drill involves hitting putts with different biases (left-to-right or right-to-left) to learn how to read and adjust for your personal bias. You can use a  system to analyze your shot patterns and identify areas where you need to improve.\n",
      "   \n",
      "  3. Speed Drill: This drill involves hitting putts at different speeds to learn how to read and adjust for the speed of the putt. You can use a  system\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63253cbc-9de3-41b9-a5c8-b672333f479c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m114"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
